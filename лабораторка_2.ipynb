{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install pygtrie"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llPVumzB3BA4",
        "outputId": "7904f2e7-1de2-44b8-ef80-ea8f1aa15732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pygtrie in /usr/local/lib/python3.10/dist-packages (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разделяем слова по символам и преобразуем их в n-граммы."
      ],
      "metadata": {
        "id": "PIvCg9xc2j3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def generate_ngrams(text, max_len):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # убираем все специальные символы и пунктуацию из текста\n",
        "    ngrams = []\n",
        "    words = text.split(' ')  # делим текст по пробелам\n",
        "    # Проходим по каждому слову\n",
        "    for word in words:\n",
        "        # Проходим по каждому символу в слове\n",
        "        for symbol in range(len(word)):\n",
        "            # Создаем n-граммы длиной от 1 до max_len\n",
        "            for n_symbol in range(1, max_len + 1):\n",
        "                if symbol + n_symbol <= len(word):  # проверяем, не выходит ли текущая n-грамма за пределы слова\n",
        "                    ngram = word[symbol:symbol+n_symbol]\n",
        "                    ngrams.append(ngram)\n",
        "\n",
        "    return ngrams"
      ],
      "metadata": {
        "id": "BSKPWaoW2WRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пишем основные функции для построения префиксного дерева, его визуализации и поиска наиболее частотных префиксов"
      ],
      "metadata": {
        "id": "79qvAZJ-39j6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pygtrie\n",
        "from graphviz import Digraph\n",
        "\n",
        "class Trie:  # реализует префиксное дерево\n",
        "    def __init__(self):\n",
        "        self.trie = pygtrie.CharTrie()  # создаем экземпляр CharTrie из библиотеки pygtrie и сохраняем его в атрибуте trie\n",
        "\n",
        "    def insert(self, ngram):  # метод для добавления n-грамм в дерево\n",
        "        if ngram in self.trie:\n",
        "            self.trie[ngram]['frequency'] += 1  # если n-грамма существует в дереве, увеличиваем ее частоту на 1\n",
        "        else:\n",
        "            self.trie[ngram] = {'frequency': 1, 'unique_ngrams': {ngram}}  # если n-граммы нет в дереве, добавляем ее с частотой 1 и множеством уникальных n-грамм, содержащим только эту n-грамму\n",
        "        for pref in range(1, len(ngram)):\n",
        "            prefix = ngram[:pref]  # проходим по всем префиксам n-граммы\n",
        "            if prefix in self.trie:  # если префикс существует, добавляем n-грамму в его множество уникальных n-грамм\n",
        "                self.trie[prefix]['unique_ngrams'].add(ngram)\n",
        "            else:  # если префикса нет, добавляем его с частотой 0 и множеством уникальных n-грамм, содержащим текущую n-грамму\n",
        "                self.trie[prefix] = {'frequency': 0, 'unique_ngrams': {ngram}}\n",
        "\n",
        "    def visualize(self):  #для визуализации префиксного дерева\n",
        "        dot = Digraph(graph_attr={'splines': 'line'})  # линии прямые\n",
        "        self._add_nodes(dot, self.trie, \"\")  # добавляем узлы и ребра в граф\n",
        "        return dot\n",
        "\n",
        "    def _add_nodes(self, dot, trie, prefix):  # метод для добавления узлов и ребер в граф\n",
        "        node_id = f'{prefix}_id'  #  идентификатор узла для текущего префикса\n",
        "        node_data = trie.get(prefix, {'frequency': 0, 'unique_ngrams': set()})  # получаем данные узла для текущего префикса, или создаем пустой узел, если префикса нет в дереве\n",
        "        dot.node(node_id, label=f\"{prefix[-1:]}\\n(freq: {node_data['frequency']}, unique: {len(node_data['unique_ngrams'])})\")  # добавляем узел в граф с меткой, содержащей префикс, частоту и количество уникальных n-грамм\n",
        "        for char in trie.iterkeys(prefix):  # проходим по всем возможным продолжениям текущего префикса\n",
        "            if char.startswith(prefix) and len(char) == len(prefix) + 1:  # проверяем, является ли char непосредственным продолжением текущего префикса\n",
        "                child_prefix = char  # устанавливаем child_prefix равным char\n",
        "                child_id = f'{child_prefix}_id'  # генерируем идентификатор для дочернего узла\n",
        "                child_data = trie.get(child_prefix, {'frequency': 0, 'unique_ngrams': set()})  # получаем данные дочернего узла\n",
        "                dot.node(child_id, label=f\"{child_prefix[-1]}\\n(freq: {child_data['frequency']}, unique: {len(child_data['unique_ngrams'])})\")  # добавляем дочерний узел в граф с соответствующей меткой\n",
        "                dot.edge(node_id, child_id)  # добавляем ребро между текущим узлом и дочерним узлом.\n",
        "                self._add_nodes(dot, trie, child_prefix)  # рекурсивно вызываем _add_nodes для дочернего узла\n",
        "\n",
        "    def find_top_prefixes(self, top_n):  # метод для нахождения префиксов с наибольшим соотношением частота/уникальность\n",
        "        prefix_ratios = []\n",
        "        for key, value in self.trie.items():\n",
        "            if value['unique_ngrams']:  # проверяем, содержит ли узел уникальные n-граммы\n",
        "                ratio = value['frequency'] / len(value['unique_ngrams'])  # вычисляем соотношение частота/уникальность для текущего префикса\n",
        "                prefix_ratios.append((key, ratio))  # добавляем префикс и его соотношение в список\n",
        "        prefix_ratios.sort(key=lambda x: x[1], reverse=True)  # сортируем список по соотношению в порядке убывания\n",
        "        return prefix_ratios[:top_n]  # возвращаем топ префиксов с наибольшим соотношением\n",
        "\n",
        "\n",
        "def main(text, max_len):\n",
        "    trie = Trie()\n",
        "    ngrams = generate_ngrams(text, max_len)\n",
        "\n",
        "    for ngram in ngrams:\n",
        "        trie.insert(ngram)\n",
        "\n",
        "    return trie"
      ],
      "metadata": {
        "id": "ODKdvtbn3OsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример использования алгоритма"
      ],
      "metadata": {
        "id": "_Taq-jUYCtGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Золушкины сестры тоже получили приглашение на бал. Они очень обрадовались и сейчас же принялись выбирать наряды и придумывать, как бы причесаться, чтобы удивить всех гостей и понравиться принцу.\"\n",
        "max_len = 5  # максимальная длина n-грамм\n",
        "trie = main(text, max_len)\n",
        "\n",
        "# Визуализация Trie\n",
        "dot = trie.visualize()\n",
        "dot.render('trie_3', format='png', view=True)  # сохраняем файл в формате png\n",
        "\n",
        "# Нахождение и вывод самых частотных префиксов\n",
        "top_prefixes = trie.find_top_prefixes(top_n=50)  # ищем 50 самых частотных префиксов\n",
        "print(\"Топ префиксы по соотношению частота/уникальность:\")\n",
        "for prefix, ratio in top_prefixes:\n",
        "    print(f\"Префикс: {prefix}, Соотношение: {ratio}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_8jFNCf365o",
        "outputId": "adcec471-9773-4fe7-a212-7cb13ab5af2e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Топ префиксы по соотношению частота/уникальность:\n",
            "Префикс: ь, Соотношение: 2.6666666666666665\n",
            "Префикс: лись, Соотношение: 2.0\n",
            "Префикс: ись, Соотношение: 2.0\n",
            "Префикс: сь, Соотношение: 2.0\n",
            "Префикс: ся, Соотношение: 2.0\n",
            "Префикс: ться, Соотношение: 2.0\n",
            "Префикс: же, Соотношение: 2.0\n",
            "Префикс: бы, Соотношение: 2.0\n",
            "Префикс: ься, Соотношение: 2.0\n",
            "Префикс: ть, Соотношение: 1.6666666666666667\n",
            "Префикс: Золуш, Соотношение: 1.0\n",
            "Префикс: олушк, Соотношение: 1.0\n",
            "Префикс: олучи, Соотношение: 1.0\n",
            "Префикс: оже, Соотношение: 1.0\n",
            "Префикс: очень, Соотношение: 1.0\n",
            "Префикс: обрад, Соотношение: 1.0\n",
            "Префикс: обы, Соотношение: 1.0\n",
            "Префикс: овали, Соотношение: 1.0\n",
            "Префикс: остей, Соотношение: 1.0\n",
            "Префикс: онрав, Соотношение: 1.0\n",
            "Префикс: лушки, Соотношение: 1.0\n",
            "Префикс: лучил, Соотношение: 1.0\n",
            "Префикс: ли, Соотношение: 1.0\n",
            "Префикс: лис, Соотношение: 1.0\n",
            "Префикс: лашен, Соотношение: 1.0\n",
            "Префикс: ушкин, Соотношение: 1.0\n",
            "Префикс: учили, Соотношение: 1.0\n",
            "Префикс: умыва, Соотношение: 1.0\n",
            "Префикс: удиви, Соотношение: 1.0\n",
            "Префикс: шкины, Соотношение: 1.0\n",
            "Префикс: шение, Соотношение: 1.0\n",
            "Префикс: кины, Соотношение: 1.0\n",
            "Префикс: как, Соотношение: 1.0\n",
            "Префикс: ины, Соотношение: 1.0\n",
            "Префикс: иняли, Соотношение: 1.0\n",
            "Префикс: инцу, Соотношение: 1.0\n",
            "Префикс: или, Соотношение: 1.0\n",
            "Префикс: иглаш, Соотношение: 1.0\n",
            "Префикс: ие, Соотношение: 1.0\n",
            "Префикс: ис, Соотношение: 1.0\n",
            "Префикс: ирать, Соотношение: 1.0\n",
            "Префикс: идумы, Соотношение: 1.0\n",
            "Префикс: ичеса, Соотношение: 1.0\n",
            "Префикс: ивить, Соотношение: 1.0\n",
            "Префикс: иться, Соотношение: 1.0\n",
            "Префикс: ны, Соотношение: 1.0\n",
            "Префикс: ни, Соотношение: 1.0\n",
            "Префикс: ние, Соотношение: 1.0\n",
            "Префикс: наряд, Соотношение: 1.0\n",
            "Префикс: нь, Соотношение: 1.0\n"
          ]
        }
      ]
    }
  ]
}